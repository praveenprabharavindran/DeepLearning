{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdu8UsFRUKr8QQUqPdKTNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenprabharavindran/MachineLearning/blob/main/Build_Train_Deploy_Neural_Network_TensorFlow/House_Price_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n",
        "* Numpy is a powerful n-dimensional array library that allows to easily create and manipulate arrays of data\n",
        "* Numpy can convert TensofFlow's native data structures, to Python native data types\n",
        "* Matplotlib is a graphics plot library"
      ],
      "metadata": {
        "id": "mpW9ctoQ2rtf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBINsiepzsra"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem statement\n",
        " Using example data, develop a model that predicts house prices basecd on the size of a house\n",
        "\n",
        "# Get Data\n",
        " In this example we will be using a truncated vesrion of the Ames dataset that only contains information on homes sold in May 2010.\n",
        "\n",
        "## About the Ames Dataset\n",
        " The Ames dataset is a widely available dataset that has become one of thye standard datasets used when predicting home prices based on features of the home. It is based on the great work of Dean De Cock. His rational and insight into this dataset can be found at  https://jse.amstat.org/v19n3/decock.pdf.\n",
        "\n",
        " ## Getting the truncated dataset we use\n",
        " This dataset can be found with the excercies files for this course. The filename is AmesHousing-05-2010.csv"
      ],
      "metadata": {
        "id": "NLhRF-Xu2-bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# prompt  user to select a file to upload, and store it to a dictionary named 'uploaded' \n",
        "# 'uploded' is a dictionary with key = filename and value = contents of the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 'iter()' function creates and iterator over the dictionary variable 'uploaded'\n",
        "# 'next()' function iterates over the uploaded variable and gets the first file\n",
        "# 'csv_housefile' variable is assigned the name of the file that was uploaded\n",
        "csv_housefile = next(iter(uploaded))\n",
        "\n",
        "\n",
        "print('User uploaded file: {name}, with lenght:{length}'.format(name=csv_housefile, length=len(uploaded[csv_housefile])))"
      ],
      "metadata": {
        "id": "sHgYQqnOye9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data into a pandas dataframe\n",
        "* Pandas allows easil review and manipulation the data \n",
        "* Check out pandas webstie: https://pandas.pydata.org/\n",
        "* Here is a [Pandas 10 minute intro](http://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) to understand how pandas, and pandas dataframes makes working with tabular data in Python easy."
      ],
      "metadata": {
        "id": "NLC4a23kYYg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_housing = pd.read_csv(csv_housefile)\n"
      ],
      "metadata": {
        "id": "jnYQcFpXYSf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Review House Price Data"
      ],
      "metadata": {
        "id": "6LQJtc_QZH4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns',None)\n",
        "df_housing.head(5)"
      ],
      "metadata": {
        "id": "tujzy3utZOdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Review Data using data_table formatter\n",
        "* Using the data_table_formatter displays the table in an interactive mode making it easier to explore and analyze dataframes\n",
        "* However this approach supports only 20 columns beyond which is fallsback to the pandas display."
      ],
      "metadata": {
        "id": "2xR5peVCb-Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import data_table\n",
        "# data_table.enable_dataframe_formatter()\n",
        "# \n",
        "# columns = df_housing.columns\n",
        "# display(df_housing[columns[:20]])"
      ],
      "metadata": {
        "id": "pL2LMdzKcIOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Pre process data\n",
        "* Among the given parameters (columns), the size of the house has the greatest impact on the cost. \n",
        "* The total square footage of the house is not immediately accessible and requires aggregating several fields together.  \n",
        "\n",
        " **Note**: There are some aggregate fields in the data that could be used to simply calucation:\n",
        "  >Total Bsmt SF = BsmtFin SF 1 + BsmtFin SF 2 + Bsmt Unf SF  \n",
        "  >Gr Liv Area = 1st Flr SF + 2nd Flr SF\n",
        "\n",
        "* In summary: \n",
        "  - total space in the house  = sum of Basement and Upper floors  \n",
        "   = Total Bsmt SF + Gr Liv Area"
      ],
      "metadata": {
        "id": "FJIfe4DnZwMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if any of the field values are null\n",
        "df_housing[['Total Bsmt SF', 'Gr Liv Area']].isnull().values.any()"
      ],
      "metadata": {
        "id": "hTLRr8fJef1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new feature column Total SF = Total Bsmt SF + Gr Liv Area\n",
        "df_housing['Total SF'] = df_housing['Total Bsmt SF'] + df_housing['Gr Liv Area']"
      ],
      "metadata": {
        "id": "gz6vA_E4e1nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the result of the abover operation\n",
        "print(df_housing[['Total SF', 'Total Bsmt SF', 'Gr Liv Area']].head(5))"
      ],
      "metadata": {
        "id": "aNEq6q3zfITE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the processed data"
      ],
      "metadata": {
        "id": "MR7p8yuPfjuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function visualizes our data and optionally a learned line\n",
        "def visualize_data(x_vals, y_vals,\n",
        "                   addn_x_vals=None, addn_y_vals=None, add_addn_reg_line=False):\n",
        "  \n",
        "  f, ax = plt.subplots(figsize=(8,8))\n",
        "  plt.plot(x_vals, y_vals, 'ro')   # red dot for each data point\n",
        "  # Optionally plot another set of data points in a different color and symbol\n",
        "  if (addn_x_vals is not None):\n",
        "    plt.plot(addn_x_vals, addn_y_vals, 'g^') # green triangles for additional data points\n",
        "    # Optionally, plot a regression line.\n",
        "    if (add_addn_reg_line):\n",
        "      x_min_index = addn_x_vals.argmin()\n",
        "      x_max_index = addn_x_vals.argmax()\n",
        "      print(x_min_index,[addn_x_vals[x_min_index],addn_y_vals[x_min_index]] ) \n",
        "      print(x_max_index,[addn_x_vals[x_max_index],addn_y_vals[x_max_index]] ) \n",
        "      plt.plot([addn_x_vals[x_min_index],addn_y_vals[x_min_index]], \n",
        "               [addn_x_vals[x_max_index],addn_y_vals[x_max_index]], \n",
        "               'b-')  # draw a blue regression line\n",
        "    \n",
        "  plt.tick_params(axis='both', which='major', labelsize=14)\n",
        "  \n",
        "  plt.show()  # now plot the line showing the data and the optional line"
      ],
      "metadata": {
        "id": "x1fzD_nEkfGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Total SF and Price\n",
        "* Using the visualize_data function we can see the relationship between Total Square Feet (Total SF) and Price.\n",
        "* As can be seen from the plot there is a linear relationship between the price and size of the house"
      ],
      "metadata": {
        "id": "eaWcOLmnkijj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot Total SF vs. Price\n",
        "visualize_data(df_housing['Total SF'], df_housing['SalePrice'],add_addn_reg_line=True)"
      ],
      "metadata": {
        "id": "-0VqsxPTkonz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "* If values are on very different scales it will be difficult for the model to determine the relationships between features. \n",
        "* With the data we have , Square Footage (SF) ranges from 800-4200, and Prices range from 80,000 to 400,0000. \n",
        "* This means there is a nearly **`100 times`** difference in scale. \n",
        "* Normalization is a process to reduce both qualtities to the same scale while preserving the differences between prices and sizes of homes. \n",
        "* This will help our model learn the relationship between price and size."
      ],
      "metadata": {
        "id": "Cenh-DhKmdFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale data so SF and Sale Price are on similar scales with values \n",
        "#  from 0.0 to 1.0\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sf_scaler = MinMaxScaler()\n",
        "sf_scaled = sf_scaler.fit_transform(df_housing['Total SF'].values.reshape(-1,1).astype(np.float64))\n",
        "    \n",
        "price_scaler = MinMaxScaler()\n",
        "price_scaled = price_scaler.fit_transform(df_housing['SalePrice'].values.reshape(-1,1).astype(np.float64))"
      ],
      "metadata": {
        "id": "gGoyqk3Ym5G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "GzcuvOlinD5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the TensorFlow Keras library\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=1, activation='linear', input_shape=(1,),\n",
        "                                kernel_initializer='random_uniform',\n",
        "                                bias_initializer='zeros'))\n"
      ],
      "metadata": {
        "id": "XlsCUvvDnUNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "K5h_MdxvqYuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "optimizer = \"sgd\"\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer )"
      ],
      "metadata": {
        "id": "M4XxQ3bnqmbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "S6RCrAk3qoeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training dataset - 70%, Testing dataset - 30%\n",
        "# we do this using the sklearn train_test_split method\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sf_train_scaled, sf_test_scaled, price_train_scaled, price_test_scaled = train_test_split(sf_scaled, \n",
        "                                                    price_scaled, \n",
        "                                                    test_size=0.3, random_state=42)\n",
        "     "
      ],
      "metadata": {
        "id": "hyERIAvpqp1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train model using data\n",
        "initial_epochs = 8\n",
        "batch_size = 10\n",
        "train_hist = model.fit(sf_train_scaled, price_train_scaled, \n",
        "                       epochs=initial_epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Is 8 epochs enough??? Maybe/Maybe not\n",
        "     "
      ],
      "metadata": {
        "id": "RcKiC4XDrEqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}